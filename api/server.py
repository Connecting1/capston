# backend/server.py (ìˆ˜ì • ë²„ì „)
from fastapi import FastAPI, WebSocket, WebSocketDisconnect, Depends, HTTPException, File, UploadFile
from fastapi.middleware.cors import CORSMiddleware
from sqlalchemy.orm import Session
from typing import List, Optional, Dict
from database import engine, get_db, SessionLocal
from pydantic import BaseModel
from datetime import datetime
import httpx
import json
import models
import socket
import asyncio
import os

# ìƒˆë¡œìš´ ëª¨ë“ˆ import
from feynman_prompts import LearningPhase, feynman_engine
from evaluation_system import evaluator
from learning_flow import flow_manager
#Rag ì‹œìŠ¤í…œ 
from rag_system import rag_system
import shutil

# ë°ì´í„°ë² ì´ìŠ¤ í…Œì´ë¸” ìƒì„±
models.Base.metadata.create_all(bind=engine)

app = FastAPI()

# uploads í´ë” ìƒì„±
os.makedirs("uploads", exist_ok=True)

# ì‹¤ì œ IP ì£¼ì†Œ í™•ì¸
def get_local_ip():
    s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
    try:
        s.connect(('8.8.8.8', 80))
        ip = s.getsockname()[0]
    finally:
        s.close()
    return ip

LOCAL_IP = get_local_ip()
print(f"Server IP: {LOCAL_IP}:8000")

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ========== ê¸°ì¡´ Pydantic ëª¨ë¸ ==========
class ChatRoomCreate(BaseModel):
    title: str

class MessageResponse(BaseModel):
    id: str
    role: str
    content: str
    created_at: datetime
    
    class Config:
        orm_mode = True

class ChatRoomResponse(BaseModel):
    id: str
    title: str
    created_at: datetime
    updated_at: datetime
    
    class Config:
        orm_mode = True

class MessageCreate(BaseModel):
    content: str
    role: str
    phase: str

# ========== ìƒˆë¡œìš´ Pydantic ëª¨ë¸ (íŒŒì¸ë§Œ) ==========
class PhaseTransitionRequest(BaseModel):
    room_id: str
    user_choice: Optional[str] = None
    message: Optional[str] = None

class PhaseResponse(BaseModel):
    current_phase: str
    next_phase: str
    instruction: str
    title: str

# ========== í‚¤ì›Œë“œ ì¶”ì¶œ í•¨ìˆ˜ (ìƒˆë¡œ ì¶”ê°€) ==========
async def extract_concept_keyword(user_message: str) -> str:
    """ì‚¬ìš©ì ì§ˆë¬¸ì—ì„œ í•µì‹¬ ê°œë… í‚¤ì›Œë“œ ì¶”ì¶œ"""
    
    extraction_prompt = f"""ë‹¤ìŒ ì§ˆë¬¸ì—ì„œ í•™ìŠµí•˜ê³ ì í•˜ëŠ” í•µì‹¬ ê°œë…/í‚¤ì›Œë“œë§Œ ì¶”ì¶œí•˜ì„¸ìš”.
ì§ˆë¬¸: {user_message}

ê·œì¹™:
- 2-3ë‹¨ì–´ ì´ë‚´ì˜ í•µì‹¬ ê°œë…ë§Œ ì¶”ì¶œ
- "ì— ëŒ€í•´", "ì•Œë ¤ì¤˜", "ì„¤ëª…í•´ì¤˜" ë“±ì€ ì œì™¸
- ëª…ì‚¬í˜•ìœ¼ë¡œ ì¶”ì¶œ
- í•œ ì¤„ë¡œë§Œ ë‹µë³€

ì˜ˆì‹œ:
ì§ˆë¬¸: "ìë£Œêµ¬ì¡°ì— ëŒ€í•´ì„œ ì•Œë ¤ì¤˜" â†’ ìë£Œêµ¬ì¡°
ì§ˆë¬¸: "ë¨¸ì‹ ëŸ¬ë‹ ì•Œê³ ë¦¬ì¦˜ ì„¤ëª…í•´ì¤˜" â†’ ë¨¸ì‹ ëŸ¬ë‹ ì•Œê³ ë¦¬ì¦˜
ì§ˆë¬¸: "ì–‘ìì—­í•™ì´ ë­ì•¼?" â†’ ì–‘ìì—­í•™

í‚¤ì›Œë“œ:"""

    try:
        async with httpx.AsyncClient() as client:
            print(f"ğŸ” í‚¤ì›Œë“œ ì¶”ì¶œ ì¤‘: '{user_message}'")
            response = await client.post(
                "http://localhost:11434/api/generate",
                json={
                    "model": "llama3.1:8b",
                    "prompt": extraction_prompt,
                    "stream": False
                },
                timeout=180.0
            )
            
            if response.status_code == 200:
                result = response.json()
                keyword = result.get("response", "").strip()
                # ì²« ì¤„ë§Œ ê°€ì ¸ì˜¤ê¸° (ì¶”ê°€ ì„¤ëª… ì œê±°)
                keyword = keyword.split('\n')[0].strip()
                # ë”°ì˜´í‘œ ì œê±°
                keyword = keyword.strip('"\'')
                print(f"âœ… ì¶”ì¶œëœ í‚¤ì›Œë“œ: '{keyword}'")
                return keyword if keyword else user_message
            else:
                print(f"âš ï¸ í‚¤ì›Œë“œ ì¶”ì¶œ ì‹¤íŒ¨ (ìƒíƒœ: {response.status_code}), ì›ë³¸ ì‚¬ìš©")
                return user_message
    except Exception as e:
        print(f"âš ï¸ í‚¤ì›Œë“œ ì¶”ì¶œ ì˜¤ë¥˜: {e}, ì›ë³¸ ì‚¬ìš©")
        return user_message

# ========== ê¸°ì¡´ ì—”ë“œí¬ì¸íŠ¸ ìœ ì§€ ==========
@app.get("/")
async def root():
    return {"message": "Backend is running", "ip": LOCAL_IP}

@app.get("/test-ollama")
async def test_ollama():
    try:
        async with httpx.AsyncClient() as client:
            response = await client.post(
                "http://localhost:11434/api/generate",
                json={
                    "model": "llama3.1:8b",
                    "prompt": "Say hello in Korean",
                    "stream": False
                },
                timeout=30.0
            )
            
            if response.status_code == 200:
                return {"status": "success", "response": response.json()}
            else:
                return {"status": "error", "code": response.status_code}
                
    except httpx.ConnectError:
        return {"status": "error", "message": "Cannot connect to Ollama"}
    except Exception as e:
        return {"status": "error", "message": str(e)}

@app.post("/api/rooms", response_model=ChatRoomResponse)
def create_room(room: ChatRoomCreate, db: Session = Depends(get_db)):
    """ìƒˆ ì±„íŒ…ë°© ìƒì„±"""
    db_room = models.ChatRoom(
        title=room.title,
        learning_phase="home"  # íŒŒì¸ë§Œ í•™ìŠµ ì´ˆê¸° ë‹¨ê³„
    )
    db.add(db_room)
    db.commit()
    db.refresh(db_room)
    return db_room

@app.get("/api/rooms", response_model=List[ChatRoomResponse])
def get_rooms(db: Session = Depends(get_db)):
    """ëª¨ë“  ì±„íŒ…ë°© ì¡°íšŒ"""
    rooms = db.query(models.ChatRoom).order_by(models.ChatRoom.updated_at.desc()).all()
    return rooms

@app.get("/api/rooms/{room_id}/messages", response_model=List[MessageResponse])
def get_messages(room_id: str, db: Session = Depends(get_db)):
    """íŠ¹ì • ì±„íŒ…ë°©ì˜ ë©”ì‹œì§€ ì¡°íšŒ"""
    messages = db.query(models.Message).filter(
        models.Message.room_id == room_id
    ).order_by(models.Message.created_at).all()
    return messages

@app.delete("/api/rooms/{room_id}")
def delete_room(room_id: str, db: Session = Depends(get_db)):
    """ì±„íŒ…ë°© ì‚­ì œ (ë©”ì‹œì§€ë„ í•¨ê»˜ ì‚­ì œë¨)"""
    room = db.query(models.ChatRoom).filter(models.ChatRoom.id == room_id).first()
    
    if not room:
        raise HTTPException(status_code=404, detail="Room not found")
    
    # CASCADE ì„¤ì • ë•ë¶„ì— ë©”ì‹œì§€ë“¤ë„ ìë™ ì‚­ì œë¨
    db.delete(room)
    db.commit()
    
    print(f"ğŸ—‘ï¸ ì±„íŒ…ë°© ì‚­ì œë¨: {room_id}")
    
    return {"status": "ok", "message": "Room deleted"}

class DeleteRoomsRequest(BaseModel):
    room_ids: List[str]

@app.post("/api/rooms/delete-multiple")
def delete_multiple_rooms(request: DeleteRoomsRequest, db: Session = Depends(get_db)):
    """ì—¬ëŸ¬ ì±„íŒ…ë°© í•œ ë²ˆì— ì‚­ì œ"""
    deleted_count = 0
    
    for room_id in request.room_ids:
        room = db.query(models.ChatRoom).filter(models.ChatRoom.id == room_id).first()
        if room:
            db.delete(room)
            deleted_count += 1
    
    db.commit()
    
    print(f"ğŸ—‘ï¸ {deleted_count}ê°œ ì±„íŒ…ë°© ì‚­ì œë¨")
    
    return {"status": "ok", "deleted_count": deleted_count}

@app.post("/api/rooms/{room_id}/messages")
def save_message(room_id: str, message: MessageCreate, db: Session = Depends(get_db)):
    """ë‹¨ìˆœ ë©”ì‹œì§€ ì €ì¥ (AI ì‘ë‹µ ì—†ì´)"""
    room = db.query(models.ChatRoom).filter(models.ChatRoom.id == room_id).first()
    
    if not room:
        raise HTTPException(status_code=404, detail="Room not found")
    
    # ë©”ì‹œì§€ ì €ì¥
    db_message = models.Message(
        room_id=room_id,
        role=message.role,
        content=message.content,
        phase=message.phase
    )
    db.add(db_message)
    
    # ë°© ì—…ë°ì´íŠ¸ ì‹œê°„ ê°±ì‹ 
    room.updated_at = datetime.utcnow()
    db.commit()
    
    print(f"ğŸ’¾ ë©”ì‹œì§€ ì €ì¥ë¨ (ë‹¨ê³„: {message.phase}): {message.content[:50]}...")
    
    return {"status": "ok", "message_id": db_message.id}

# ========== ìƒˆë¡œìš´ íŒŒì¸ë§Œ í•™ìŠµ ì—”ë“œí¬ì¸íŠ¸ ==========
@app.post("/api/learning/transition", response_model=PhaseResponse)
async def transition_phase(
    request: PhaseTransitionRequest,
    db: Session = Depends(get_db)
):
    """í•™ìŠµ ë‹¨ê³„ ì „í™˜"""
    room = db.query(models.ChatRoom).filter(
        models.ChatRoom.id == request.room_id
    ).first()
    
    if not room:
        raise HTTPException(status_code=404, detail="Room not found")
    
    # í˜„ì¬ ë‹¨ê³„ ê°€ì ¸ì˜¤ê¸°
    current_phase = LearningPhase(room.learning_phase or "home")
    
    # ë‹¤ìŒ ë‹¨ê³„ ê²°ì •
    next_phase = flow_manager.get_next_phase(current_phase, request.user_choice)
    
    # DB ì—…ë°ì´íŠ¸
    room.learning_phase = next_phase.value
    db.commit()
    
    return PhaseResponse(
        current_phase=current_phase.value,
        next_phase=next_phase.value,
        instruction=flow_manager.get_phase_instruction(next_phase),
        title=flow_manager.get_phase_title(next_phase)
    )

@app.get("/api/learning/phase/{room_id}")
async def get_current_phase(room_id: str, db: Session = Depends(get_db)):
    """í˜„ì¬ í•™ìŠµ ë‹¨ê³„ ì¡°íšŒ"""
    room = db.query(models.ChatRoom).filter(
        models.ChatRoom.id == room_id
    ).first()
    
    if not room:
        raise HTTPException(status_code=404, detail="Room not found")
    
    phase = LearningPhase(room.learning_phase or "home")
    
    return {
        "phase": phase.value,
        "instruction": flow_manager.get_phase_instruction(phase),
        "title": flow_manager.get_phase_title(phase),
        "can_go_back": flow_manager.can_go_back(phase)
    }

@app.post("/api/rooms/{room_id}/upload-pdf")
async def upload_pdf(
    room_id: str,
    file: UploadFile = File(...),
    db: Session = Depends(get_db)
):
    """PDF íŒŒì¼ ì—…ë¡œë“œ ë° RAG ì‹œìŠ¤í…œì— ë“±ë¡"""
    
    # íŒŒì¼ í˜•ì‹ í™•ì¸
    if not file.filename.endswith('.pdf'):
        raise HTTPException(status_code=400, detail="PDF íŒŒì¼ë§Œ ì—…ë¡œë“œ ê°€ëŠ¥í•©ë‹ˆë‹¤")
    
    # íŒŒì¼ í¬ê¸° í™•ì¸ (10MB ì œí•œ)
    file_size = 0
    chunk_size = 1024 * 1024  # 1MB
    temp_file = f"uploads/temp_{room_id}.pdf"
    
    try:
        with open(temp_file, "wb") as buffer:
            while chunk := await file.read(chunk_size):
                file_size += len(chunk)
                if file_size > 10 * 1024 * 1024:  # 10MB
                    os.remove(temp_file)
                    raise HTTPException(status_code=400, detail="íŒŒì¼ í¬ê¸°ëŠ” 10MB ì´í•˜ì—¬ì•¼ í•©ë‹ˆë‹¤")
                buffer.write(chunk)
        
        # RAG ì‹œìŠ¤í…œì— PDF ì¶”ê°€
        success = rag_system.add_pdf_to_collection(room_id, temp_file)
        
        if success:
            # DB ì—…ë°ì´íŠ¸
            room = db.query(models.ChatRoom).filter(models.ChatRoom.id == room_id).first()
            if room:
                room.has_pdf = True
                db.commit()
            
            print(f"âœ… PDF ì—…ë¡œë“œ ì„±ê³µ: {file.filename} (Room: {room_id})")
            return {"status": "success", "message": "PDF ì—…ë¡œë“œ ì™„ë£Œ"}
        else:
            raise HTTPException(status_code=500, detail="PDF ì²˜ë¦¬ ì‹¤íŒ¨")
            
    except HTTPException:
        raise
    except Exception as e:
        print(f"âŒ PDF ì—…ë¡œë“œ ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=f"ì—…ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
    finally:
        # ì„ì‹œ íŒŒì¼ ì‚­ì œ
        if os.path.exists(temp_file):
            os.remove(temp_file)

# ========== ìˆ˜ì •ëœ WebSocket (íŒŒì¸ë§Œ í†µí•©) ==========
@app.websocket("/ws/chat/{room_id}")
async def websocket_endpoint_with_feynman(
    websocket: WebSocket, 
    room_id: str
):
    await websocket.accept()
    print(f"âœ… WebSocket ì—°ê²°ë¨ (Room: {room_id})")

    db = SessionLocal()
    
    try:
        room = db.query(models.ChatRoom).filter(models.ChatRoom.id == room_id).first()
        if not room:
            await websocket.send_json({"error": "Room not found"})
            await websocket.close()
            return
        
        while True:
            data = await websocket.receive_text()
            print(f"ğŸ“¥ ë°›ì€ ë©”ì‹œì§€ (Room {room_id}): {data}")
            
            message_data = json.loads(data)
            
            # ë©”ì‹œì§€ íƒ€ì… í™•ì¸
            msg_type = message_data.get("type", "message")
            
            if msg_type == "phase_transition":
                # ë‹¨ê³„ ì „í™˜ ìš”ì²­
                user_choice = message_data.get("choice")
                current_phase = LearningPhase(room.learning_phase or "home")
                next_phase = flow_manager.get_next_phase(current_phase, user_choice)
                
                room.learning_phase = next_phase.value
                db.commit()
                
                await websocket.send_json({
                    "type": "phase_changed",
                    "phase": next_phase.value,
                    "instruction": flow_manager.get_phase_instruction(next_phase),
                    "title": flow_manager.get_phase_title(next_phase)
                })
                continue
            
            # ì¼ë°˜ ë©”ì‹œì§€ ì²˜ë¦¬
            try:
                user_message = message_data["message"]
            except KeyError as e:
                await websocket.send_json({
                    "type": "error",
                    "content": "Invalid message format"
                })
                continue

            # RAG ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰ (ì¶”ê°€)
            rag_context = ""
            if rag_system.has_pdf(room_id):
                contexts = rag_system.search(room_id, user_message, n_results=5)
                if contexts:
                    rag_context = "\n\n**ì°¸ê³  ìë£Œ:**\n"
                    for ctx in contexts:
                        rag_context += f"[Page {ctx['page']}] {ctx['content'][:200]}...\n\n"
                    print(f"ğŸ“š RAG ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€ë¨ ({len(contexts)}ê°œ)")
            
            # í˜„ì¬ í•™ìŠµ ë‹¨ê³„ í™•ì¸
            db.refresh(room)  # DB 
            current_phase = LearningPhase(room.learning_phase or "home")
            
            # ì‚¬ìš©ì ë©”ì‹œì§€ ì €ì¥ (ë‹¨ê³„ ì •ë³´ í¬í•¨)
            user_msg = models.Message(
                room_id=room_id,
                role="user",
                content=user_message,
                phase=current_phase.value if hasattr(models.Message, 'phase') else None,
                is_explanation=(current_phase in [
                    LearningPhase.FIRST_EXPLANATION,
                    LearningPhase.SECOND_EXPLANATION
                ]) if hasattr(models.Message, 'is_explanation') else None
            )
            db.add(user_msg)
            db.commit()
            print(f"ğŸ’¾ ì‚¬ìš©ì ë©”ì‹œì§€ ì €ì¥ë¨ (ë‹¨ê³„: {current_phase.value})")
            
            if current_phase == LearningPhase.HOME:
                # í‚¤ì›Œë“œ ì¶”ì¶œ
                concept_keyword = await extract_concept_keyword(user_message)

                # ê°œë… ì €ì¥
                room.current_concept = user_message
                room.learning_phase = LearningPhase.KNOWLEDGE_CHECK.value
                db.commit()
    
                print(f"ğŸ’¾ ê°œë… ì €ì¥: '{concept_keyword}'")
                print(f"ğŸ”„ ë‹¨ê³„ ì „í™˜: HOME â†’ KNOWLEDGE_CHECK")
    
            # AI ì‘ë‹µ ì—†ì´ ë°”ë¡œ ë‹¨ê³„ ì „í™˜ ì•Œë¦¼
                await websocket.send_json({
                    "type": "phase_changed",
                    "phase": LearningPhase.KNOWLEDGE_CHECK.value,
                    "instruction": flow_manager.get_phase_instruction(LearningPhase.KNOWLEDGE_CHECK),
                    "title": flow_manager.get_phase_title(LearningPhase.KNOWLEDGE_CHECK)
                })
    
                # ë‹¨ìˆœ ì•ˆë‚´ ë©”ì‹œì§€ë§Œ ì „ì†¡
                simple_response = f"'{concept_keyword}'ì— ëŒ€í•´ í•™ìŠµí•˜ì‹œëŠ”êµ°ìš”! ì´ ê°œë…ì— ëŒ€í•´ ì–¼ë§ˆë‚˜ ì•Œê³  ê³„ì‹ ê°€ìš”?"
    
                ai_msg = models.Message(
                    room_id=room_id,
                    role="assistant",
                    content=simple_response,
                    phase=LearningPhase.KNOWLEDGE_CHECK.value if hasattr(models.Message, 'phase') else None
                )
                db.add(ai_msg)
                room.updated_at = datetime.utcnow()
                db.commit()
    
                await websocket.send_json({
                    "type": "stream",
                    "content": simple_response,
                    "phase": LearningPhase.KNOWLEDGE_CHECK.value
                })
    
                await websocket.send_json({
                    "type": "complete",
                    "phase": LearningPhase.KNOWLEDGE_CHECK.value
                })
    
                print("âœ… KNOWLEDGE_CHECK ë‹¨ê³„ë¡œ ì „í™˜ ì™„ë£Œ")
                continue  # Ollama í˜¸ì¶œ ì—†ì´ ë‹¤ìŒ ë©”ì‹œì§€ ëŒ€ê¸°


            # ì‚¬ìš©ì ì„¤ëª… ë¶„ì„ (ì„¤ëª… ë‹¨ê³„ì¸ ê²½ìš°)
            analysis = None
            if current_phase in [LearningPhase.FIRST_EXPLANATION, LearningPhase.SECOND_EXPLANATION]:
                analysis = evaluator.analyze_explanation(user_message)
                print(f"ğŸ“Š ì„¤ëª… ë¶„ì„ ì™„ë£Œ")
            
            # ì»¨í…ìŠ¤íŠ¸ ì¤€ë¹„
            context = {
                "concept": room.current_concept if hasattr(room, 'current_concept') else None,
                "knowledge_level": room.knowledge_level if hasattr(room, 'knowledge_level') else 0,
                "analysis": analysis,
                "phase": current_phase.value
            }
            
            # íŒŒì¸ë§Œ í”„ë¡¬í”„íŠ¸ ê°€ì ¸ì˜¤ê¸°
            system_prompt = feynman_engine.get_prompt_for_phase(current_phase, context)
            
            # Ollama API í˜¸ì¶œ
            ai_response = ""
            try:
                async with httpx.AsyncClient() as client:
                    print("ğŸ¤– Ollama ìš”ì²­ ì¤‘ (íŒŒì¸ë§Œ ëª¨ë“œ)...")
                    
                    # Ollamaì— ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ í¬í•¨
                    if rag_context:
                        full_prompt = f"{system_prompt}\n\n{rag_context}\n\nì‚¬ìš©ì: {user_message}\n\nAI:"
                    else:
                        full_prompt = f"{system_prompt}\n\nì‚¬ìš©ì: {user_message}\n\nAI:"
                    print(f"ğŸ“ í”„ë¡¬í”„íŠ¸ ê¸¸ì´: {len(full_prompt)} ë¬¸ì")
                    print(f"ğŸ“ í”„ë¡¬í”„íŠ¸ ë¯¸ë¦¬ë³´ê¸°:\n{full_prompt[:500]}...")
                    
                    async with client.stream(
                        "POST",
                        "http://localhost:11434/api/generate",
                        json={
                            "model": "llama3.1:8b",
                            "prompt": full_prompt,
                            "stream": True
                        },
                        timeout=httpx.Timeout(300.0, connect=60.0)
                    ) as response:
                        
                        print(f"ğŸ“¡ Ollama ì‘ë‹µ ìƒíƒœ: {response.status_code}")
                        
                        if response.status_code != 200:
                            await websocket.send_json({
                                "type": "error",
                                "content": f"Ollama error: {response.status_code}"
                            })
                            continue
                        
                        async for line in response.aiter_lines():
                            if line.strip():
                                try:
                                    chunk_data = json.loads(line)
                                    
                                    if "response" in chunk_data:
                                        chunk = chunk_data["response"]
                                        ai_response += chunk
                                        
                                        await websocket.send_json({
                                            "type": "stream",
                                            "content": chunk,
                                            "phase": current_phase.value
                                        })
                                    
                                    if chunk_data.get("done", False):
                                        break
                                        
                                except json.JSONDecodeError:
                                    continue
                
                # AI ì‘ë‹µ ì €ì¥
                ai_msg = models.Message(
                    room_id=room_id,
                    role="assistant",
                    content=ai_response,
                    phase=current_phase.value if hasattr(models.Message, 'phase') else None
                )
                db.add(ai_msg)
                room.updated_at = datetime.utcnow()
                db.commit()
                print(f"ğŸ’¾ AI ì‘ë‹µ ì €ì¥ë¨ (ë‹¨ê³„: {current_phase.value})")
                
                # í‰ê°€ ë‹¨ê³„ì¸ ê²½ìš° í‰ê°€ ê²°ê³¼ ì €ì¥
                if current_phase == LearningPhase.EVALUATION and analysis:
                    if hasattr(models, 'LearningEvaluation'):
                        evaluation = models.LearningEvaluation(
                            room_id=room_id,
                            message_id=user_msg.id,
                            strengths=analysis.get("strengths", []),
                            weaknesses=analysis.get("weaknesses", []),
                            suggestions=analysis.get("suggestions", [])
                        )
                        db.add(evaluation)
                        db.commit()
                        print(f"ğŸ“Š í‰ê°€ ê²°ê³¼ ì €ì¥ë¨")
                
                await websocket.send_json({
                    "type": "complete",
                    "phase": current_phase.value
                })
                print("âœ‰ï¸ ì™„ë£Œ ì‹ í˜¸ ì „ì†¡")
                
            except Exception as e:
                import traceback
                error_detail = traceback.format_exc()
                print(f"âŒ ì²˜ë¦¬ ì˜¤ë¥˜ ë°œìƒ!")
                print(f"âŒ ì—ëŸ¬ íƒ€ì…: {type(e).__name__}")
                print(f"âŒ ì—ëŸ¬ ë©”ì‹œì§€: {str(e)}")
                print(f"âŒ ìƒì„¸ ìŠ¤íƒ:")
                print(error_detail)
    
                await websocket.send_json({
                    "type": "error",
                    "content": f"Error: {str(e)}"
                })
                
    except WebSocketDisconnect:
        print(f"ğŸ”Œ WebSocket ì—°ê²° ëŠê¹€ (Room: {room_id})")
    except Exception as e:
        print(f"âŒ WebSocket ì˜¤ë¥˜: {e}")
    finally:
        db.close()

if __name__ == "__main__":
    import uvicorn
    print("="*50)
    print(f"ğŸš€ íŒŒì¸ë§Œ í•™ìŠµë²• ì„œë²„ ì‹œì‘")
    print(f"ğŸ“ Local IP: http://{LOCAL_IP}:8000")
    print(f"ğŸ“ Localhost: http://localhost:8000")
    print(f"ğŸ§ª Ollama í…ŒìŠ¤íŠ¸: http://localhost:8000/test-ollama")
    print(f"ğŸ“š API ë¬¸ì„œ: http://localhost:8000/docs")
    print("="*50)
    print("ğŸ“Œ í•™ìŠµ API:")
    print(f"  - í˜„ì¬ ë‹¨ê³„: GET /api/learning/phase/{{room_id}}")
    print(f"  - ë‹¨ê³„ ì „í™˜: POST /api/learning/transition")
    print("="*50)
    
    uvicorn.run(app, host="0.0.0.0", port=8000, log_level="info")